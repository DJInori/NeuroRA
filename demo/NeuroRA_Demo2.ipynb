{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 2: a demo based on Haxby fMRI data\n",
    "Here is a demo based on the publicly available Haxby fMRI datasets. (Reference: Haxby, J. V. (2001). Distributed and Overlapping Representations of Faces and Objects in Ventral Temporal Cortex. Science, 293(5539), 2425â€“2430.) Nilearn has been used to load this dataset and plot some results in this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "' a demo based on Haxby fMRI data '\n",
    "# Users can learn how to use Neurora to do research based on fMRI data.\n",
    "\n",
    "__author__ = 'Zitong Lu'\n",
    "\n",
    "from nilearn import datasets, plotting\n",
    "from nilearn.image import index_img, mean_img\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from neurora.stuff import get_affine, datamask\n",
    "from neurora.nps_cal import nps_fmri, nps_fmri_roi\n",
    "from neurora.rsa_plot import plot_rdm\n",
    "from neurora.rdm_cal import fmriRDM_roi, fmriRDM\n",
    "from neurora.corr_cal_by_rdm import fmrirdms_corr\n",
    "from neurora.nii_save import corr_save_nii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Loading example data\n",
    "Here, we use Nilearn toolbox for loading data and processing. You can learn this process from Nilearn (http://nilearn.github.io/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Haxby dataset (here, we only use subject2's data for this example)\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "\n",
    "# load the fMRI data filename & mask data filename\n",
    "func_filename = haxby_dataset.func[0]\n",
    "mask_filename = haxby_dataset.mask\n",
    "\n",
    "# read label information of the experiment\n",
    "labelinfo = pd.read_csv(haxby_dataset.session_target[0], sep=' ')\n",
    "labels = labelinfo['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mask data NumPy array\n",
    "maskdata = nib.load(mask_filename).get_data()\n",
    "\n",
    "# get the size of the data\n",
    "nx, ny, nz = maskdata.shape\n",
    "\n",
    "# labels of seven ategories\n",
    "categories = [\"face\", \"cat\", \"house\", \"chair\", \"shoe\", \"bottle\", \"scissors\"]\n",
    "# numbe of conidtions: 7\n",
    "ncon = len(categories)\n",
    "\n",
    "# get fmri data under 7 conditions\n",
    "# here we average the data under different conditions\n",
    "fmri_data = np.full([ncon, nx, ny, nz], np.nan)\n",
    "\n",
    "for i in range(ncon):\n",
    "    img = mean_img(index_img(func_filename, labels.isin([categories[i]])))\n",
    "    fmri_data[i] = datamask(img.get_data(), maskdata)\n",
    "\n",
    "# get fmri data under 'face'-condition\n",
    "face_img = nib.Nifti1Image(fmri_data[0], affine=img.affine)\n",
    "# have a look\n",
    "plotting.plot_epi(face_img)\n",
    "plotting.show()\n",
    "\n",
    "# reshaoe the data: [ncon, nx, ny, nz] -> [ncon, nsubs, nx, ny, nz]\n",
    "# here just one subject's data\n",
    "fmri_data = np.reshape(fmri_data, [ncon, 1, nx, ny, nz])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Calculating the neural pattern similarity (for ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mask of 'mask_face' in the dataset\n",
    "mask_face_filename = haxby_dataset.mask_face[0]\n",
    "mask_face_data = nib.load(mask_face_filename).get_data()\n",
    "\n",
    "# get input data under two condition\n",
    "# here, \"face\"-condition vs. \"scissors\"-condition\n",
    "nps_fmri_data = fmri_data[[0, 6]]\n",
    "\n",
    "# calculate the neural pattern similarity (NPS) for ROI between two stimulus\n",
    "nps_roi = nps_fmri_roi(nps_fmri_data, mask_face_data)\n",
    "\n",
    "# print the NPS result\n",
    "print(nps_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Calculating the neural pattern similarity (Searchlight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the neural pattern similarity (NPS) between two stimulus\n",
    "nps = nps_fmri(nps_fmri_data)\n",
    "\n",
    "# convert the NPS results into a .nii file\n",
    "savefilename = \"demo2_nps_img\"\n",
    "affine = get_affine(mask_filename)\n",
    "corr_save_nii(nps[0], filename=savefilename, affine=affine, size=[nx, ny, nz], smooth=False, plotrlt=False)\n",
    "\n",
    "# have a look\n",
    "plotting.plot_epi(savefilename+\".nii\")\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Calculating the RDM for ROI and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mask of \"mask_vt\" in the dataset\n",
    "mask_vt_filename = haxby_dataset.mask_face[0]\n",
    "mask_vt_data = nib.load(mask_vt_filename).get_data()\n",
    "\n",
    "# calculate the RDM for ROI\n",
    "rdm_roi = fmriRDM_roi(fmri_data, mask_vt_data, abs=False)\n",
    "\n",
    "# plot the RDM\n",
    "plot_rdm(rdm_roi, rescale=True, conditions=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Calculating the RDM by Searchlight and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the RDMs by Searchlight\n",
    "fmri_RDMs = fmriRDM(fmri_data)\n",
    "\n",
    "# plot one of the RDMs\n",
    "plot_rdm(fmri_RDMs[20, 30, 30], rescale=True, conditions=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Calculating the representational similarities between a coding model and neural activities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RDM for \"animate-inanimate\" coding model\n",
    "# which means the representations of animate matters are highly similar\n",
    "# and the representations of inanimate matters are highly similar\n",
    "model_RDM = np.array([[0, 0, 1, 1, 1, 1, 1],\n",
    "                      [0, 0, 1, 1, 1, 1, 1],\n",
    "                      [1, 1, 0, 0, 0, 0, 0],\n",
    "                      [1, 1, 0, 0, 0, 0, 0],\n",
    "                      [1, 1, 0, 0, 0, 0, 0],\n",
    "                      [1, 1, 0, 0, 0, 0, 0],\n",
    "                      [1, 1, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# plot the model RDM\n",
    "plot_rdm(model_RDM, conditions=categories)\n",
    "\n",
    "# calculate the similarities between model RDM and searchlight RDMs\n",
    "corrs = fmrirdms_corr(model_RDM, fmri_RDMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Saving the RSA result and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the filename of anatomical image as the background for plotting\n",
    "ant_filename = haxby_dataset.anat[0]\n",
    "\n",
    "# get the affine info\n",
    "affine = get_affine(mask_filename)\n",
    "\n",
    "# save the RSA result as a .nii file\n",
    "# and visualize the result automatically\n",
    "# p < 0.05, FDR-correct\n",
    "rsarltfilename = \"demo2_rsarlt_img.nii\"\n",
    "img = corr_save_nii(corrs, filename=rsarltfilename, affine=affine, corr_mask=mask_filename, size=[40, 64, 64], p=0.001, plotrlt=True, img_background=ant_filename)\n",
    "\n",
    "# Users can plot the RSA results independently by functions below\n",
    "from neurora.rsa_plot import plot_brainrsa_regions\n",
    "from neurora.rsa_plot import plot_brainrsa_montage\n",
    "from neurora.rsa_plot import plot_brainrsa_glass\n",
    "from neurora.rsa_plot import plot_brainrsa_surface\n",
    "\n",
    "# here use a [5, 5, 5] cube to remove the significant area smaller than it\n",
    "# before filtering\n",
    "plot_brainrsa_montage(rsarltfilename, slice=[[-25], 0, 0], background=ant_filename)\n",
    "# after filtering\n",
    "plot_brainrsa_montage(rsarltfilename, threshold=125, slice=[[-25], 0, 0], background=ant_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
